{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from simpletransformers.ner import NERModel, NERArgs\n",
    "\n",
    "_NER_TAGS = [\"O\", \"B_C\", \"B_P\", \"I_C\", \"I_P\"]\n",
    "ner_args = NERArgs()\n",
    "ner_args.max_seq_length = 512\n",
    "test_ner = NERModel(\"bert\", 'model_seq_512/save_model', args=ner_args, use_cuda=torch.cuda.is_available(), labels=_NER_TAGS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tag_html_format(predict_list, pos=False): # get ist of tuple 1 sentent [(word, pos, tag), .....]\n",
    "    text_result = \"\"\n",
    "    label_start = \"\"\n",
    "    start_tag = False\n",
    "    tag_label = \"\"\n",
    "        \n",
    "    for token in predict_list: # list of tuple\n",
    "        if pos == True:\n",
    "            word = token[0]\n",
    "            tag = token[2]\n",
    "        else:\n",
    "            word = token[0]\n",
    "            tag = token[1]\n",
    "        \n",
    "        if tag == \"O\":\n",
    "            if start_tag == True :\n",
    "                label_end = \"</claim>\" if label_start == \"<claim>\" else \"</premise>\"\n",
    "                text_result += label_end\n",
    "                text_result += word\n",
    "                start_tag = False\n",
    "            else:\n",
    "                text_result += word\n",
    "        else:\n",
    "            if start_tag == False:\n",
    "                tag_label = tag.split(\"-\")[1]  #I-c  = c \n",
    "                label_start = \"<claim>\" if tag_label == \"c\" else \"<premise>\"\n",
    "                text_result += label_start\n",
    "                text_result += word\n",
    "                start_tag = True\n",
    "            else:\n",
    "                if tag_label != tag.split(\"-\")[1]: #กรณีที่tag ต่างกันอยู่ติดกัน\n",
    "                    label_end = \"</claim>\" if label_start == \"<claim>\" else \"</premise>\"\n",
    "                    text_result += label_end\n",
    "                    tag_label = tag.split(\"-\")[1]  #I-c  = c \n",
    "                    label_start = \"<claim>\" if tag_label == \"c\" else \"<premise>\"\n",
    "                    text_result += label_start\n",
    "                    text_result += word\n",
    "                    start_tag = True\n",
    "                else:\n",
    "                    text_result += word\n",
    "     \n",
    "    if start_tag == True:\n",
    "        label_end = \"</claim>\" if label_start == \"<claim>\" else \"</premise>\"\n",
    "        text_result += label_end\n",
    "                \n",
    "    return text_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_text(text):\n",
    "    predict_text = []\n",
    "    text_token = word_tokenize(text)\n",
    "    predictions, raw_outputs = test_ner.predict([text_token], split_on_space=False)\n",
    "    # convert [{}] to [()]\n",
    "    # convert B_C to B-c\n",
    "    for pred_dict in predictions[0]:\n",
    "        for word, label in pred_dict.items():\n",
    "             label = label.capitalize().replace('_', '-')\n",
    "             predict_text.append((word, label))\n",
    "    return predict_text, tag_html_format(predict_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:07<00:00,  7.77s/it]\n",
      "Running Prediction: 100%|██████████| 1/1 [00:02<00:00,  2.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('การ', 'B-c'), ('ใช้', 'I-c'), ('ถุง', 'I-c'), ('พ', 'I-c'), ('ลา', 'I-c'), ('สติ', 'I-c'), ('ด', 'I-c'), ('แทน', 'I-c'), ('ถุง', 'I-c'), ('ผ้า', 'I-c'), ('ผม', 'I-c'), ('คิด', 'I-c'), ('ว่า', 'I-p'), ('มัน', 'I-p'), ('จะ', 'I-p'), ('ทำให้', 'I-p'), ('ช่วย', 'I-p'), ('ลด', 'I-p'), ('โลก', 'I-p'), ('ร้อน', 'I-p'), ('ได้', 'I-p'), ('มากขึ้น', 'I-p')]\n",
      "----\n",
      "<claim>การใช้ถุงพลาสติดแทนถุงผ้าผมคิด</claim><premise>ว่ามันจะทำให้ช่วยลดโลกร้อนได้มากขึ้น</premise>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from pythainlp.tokenize import word_tokenize\n",
    "\n",
    "text = \"การใช้ถุงพลาสติดแทนถุงผ้าผมคิดว่ามันจะทำให้ช่วยลดโลกร้อนได้มากขึ้น\"\n",
    "\n",
    "pred_text, pred_tag = predict_text(text)\n",
    "print(pred_text)\n",
    "print(\"----\")\n",
    "print(pred_tag)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "a6dc3a5d5e5e7987cc7d18355d6f408e2f42f41b0aca7d07c9009e9d98d8dd16"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 ('argument')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
