{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dill\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "552\n",
      "138\n",
      "[('ถ้า', 'B-c'), ('เดินทาง', 'I-c'), ('กลางคืน', 'I-c'), ('ก็', 'I-c'), ('รถทัวร์', 'I-c'), ('ครับ', 'I-c'), (' ', 'I-c'), (' ', 'O'), ('เพราะ', 'B-p'), ('รถ', 'I-p'), ('ไม่', 'I-p'), ('เยอะ', 'I-p'), (' ', 'I-p'), ('ความเสี่ยง', 'I-p'), ('การ', 'I-p'), ('เกิด', 'I-p'), ('อุบัติ', 'I-p'), ('ห', 'I-p'), ('ตุ', 'I-p'), ('ก็', 'I-p'), ('น้อย', 'I-p'), ('(', 'I-p'), ('มั้ง', 'I-p'), (')', 'I-p'), (' ', 'I-p'), (' ', 'O'), ('ถ้า', 'B-c'), ('กลางวัน', 'I-c'), ('ก็', 'I-c'), ('เครื่องบิน', 'I-c'), ('ครับ', 'I-c'), (' ', 'I-c'), (' ', 'O'), ('เพราะ', 'B-p'), (' ', 'I-p'), ('มัน', 'I-p'), ('ใช้เวลา', 'I-p'), ('น้อย', 'I-p'), ('จะ', 'I-p'), ('ได้', 'I-p'), ('มี', 'I-p'), ('เวลา', 'I-p'), ('ระหว่าง', 'I-p'), ('วัน', 'I-p'), ('เยอะ', 'I-p'), ('ๆ', 'I-p'), (' ', 'I-p')]\n"
     ]
    }
   ],
   "source": [
    "path_name = \"../dataset/data/\"\n",
    "\n",
    "with open(path_name + 'comment-pos.data', 'rb') as file:\n",
    "    datatofile = dill.load(file)\n",
    "\n",
    "tagged_sents = []\n",
    "for data in datatofile:\n",
    "    text_inside = []\n",
    "    for word, pos, label in data:\n",
    "        text_inside.append((word, label))\n",
    "    tagged_sents.append(text_inside)\n",
    "\n",
    "train_sents, test_sents = train_test_split(tagged_sents, test_size=0.2, random_state=42)\n",
    "print(len(train_sents))\n",
    "print(len(test_sents))\n",
    "print(train_sents[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "_NER_TAGS = [\n",
    "        \"O\",\n",
    "        \"B_C\",\n",
    "        \"B_P\",\n",
    "        \"I_C\",\n",
    "        \"I_P\"\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_simple_transformer_format(sentences):\n",
    "    sentence_id = []\n",
    "    words = []\n",
    "    labels = []\n",
    "\n",
    "    for idx, sents in enumerate(sentences):\n",
    "        for word, label in sents:\n",
    "            label = label.upper().replace(\"-\", \"_\")\n",
    "            sentence_id.append(idx)\n",
    "            words.append(word)\n",
    "            labels.append(label)\n",
    "    return pd.DataFrame(\n",
    "        {\"sentence_id\": sentence_id, \"words\": words, \"labels\": labels}\n",
    "    )    \n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence_id</th>\n",
       "      <th>words</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>อะไหล่</td>\n",
       "      <td>B_C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>เทอร์โบ</td>\n",
       "      <td>I_C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>I_C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>อี</td>\n",
       "      <td>I_C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>ซุ</td>\n",
       "      <td>I_C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37405</th>\n",
       "      <td>551</td>\n",
       "      <td>ทำ</td>\n",
       "      <td>I_P</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37406</th>\n",
       "      <td>551</td>\n",
       "      <td>อะไร</td>\n",
       "      <td>I_P</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37407</th>\n",
       "      <td>551</td>\n",
       "      <td>ได้</td>\n",
       "      <td>I_P</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37408</th>\n",
       "      <td>551</td>\n",
       "      <td>หลายอย่าง</td>\n",
       "      <td>I_P</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37409</th>\n",
       "      <td>551</td>\n",
       "      <td></td>\n",
       "      <td>I_P</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>37410 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       sentence_id      words labels\n",
       "0                0     อะไหล่    B_C\n",
       "1                0    เทอร์โบ    I_C\n",
       "2                0               I_C\n",
       "3                0         อี    I_C\n",
       "4                0         ซุ    I_C\n",
       "...            ...        ...    ...\n",
       "37405          551         ทำ    I_P\n",
       "37406          551       อะไร    I_P\n",
       "37407          551        ได้    I_P\n",
       "37408          551  หลายอย่าง    I_P\n",
       "37409          551               I_P\n",
       "\n",
       "[37410 rows x 3 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ = convert_to_simple_transformer_format(train_sents)\n",
    "train_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_ = convert_to_simple_transformer_format(test_sents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at monsoon-nlp/bert-base-thai were not used when initializing BertForTokenClassification: ['cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.predictions.decoder.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForTokenClassification were not initialized from the model checkpoint at monsoon-nlp/bert-base-thai and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "100%|██████████| 2/2 [00:08<00:00,  4.49s/it]\n",
      "C:\\Users\\pitiw\\miniconda3\\envs\\argument\\lib\\site-packages\\transformers\\optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Epochs 0/100. Running Loss:    1.2705: 100%|██████████| 46/46 [00:35<00:00,  1.31it/s]\n",
      "Epochs 1/100. Running Loss:    0.9079: 100%|██████████| 46/46 [00:32<00:00,  1.41it/s]\n",
      "Epochs 2/100. Running Loss:    0.8247: 100%|██████████| 46/46 [00:32<00:00,  1.40it/s]\n",
      "Epochs 3/100. Running Loss:    1.1194:  11%|█         | 5/46 [00:04<00:34,  1.19it/s]\n",
      "Epoch 4 of 100:   3%|▎         | 3/100 [01:53<1:01:24, 37.98s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\pitiw\\Desktop\\project-argument-tagger\\bert\\bert_argument.ipynb Cell 7'\u001b[0m in \u001b[0;36m<cell line: 17>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/pitiw/Desktop/project-argument-tagger/bert/bert_argument.ipynb#ch0000006?line=11'>12</a>\u001b[0m model \u001b[39m=\u001b[39m NERModel(\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/pitiw/Desktop/project-argument-tagger/bert/bert_argument.ipynb#ch0000006?line=12'>13</a>\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mbert\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mmonsoon-nlp/bert-base-thai\u001b[39m\u001b[39m\"\u001b[39m, args\u001b[39m=\u001b[39mner_args, use_cuda\u001b[39m=\u001b[39mtorch\u001b[39m.\u001b[39mcuda\u001b[39m.\u001b[39mis_available(), labels\u001b[39m=\u001b[39m_NER_TAGS\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/pitiw/Desktop/project-argument-tagger/bert/bert_argument.ipynb#ch0000006?line=13'>14</a>\u001b[0m )\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/pitiw/Desktop/project-argument-tagger/bert/bert_argument.ipynb#ch0000006?line=15'>16</a>\u001b[0m \u001b[39m# Train the model\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/pitiw/Desktop/project-argument-tagger/bert/bert_argument.ipynb#ch0000006?line=16'>17</a>\u001b[0m model\u001b[39m.\u001b[39;49mtrain_model(train_)\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\argument\\lib\\site-packages\\simpletransformers\\ner\\ner_model.py:458\u001b[0m, in \u001b[0;36mNERModel.train_model\u001b[1;34m(self, train_data, output_dir, show_running_loss, args, eval_data, verbose, **kwargs)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/pitiw/miniconda3/envs/argument/lib/site-packages/simpletransformers/ner/ner_model.py?line=453'>454</a>\u001b[0m train_dataset \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mload_and_cache_examples(train_data)\n\u001b[0;32m    <a href='file:///c%3A/Users/pitiw/miniconda3/envs/argument/lib/site-packages/simpletransformers/ner/ner_model.py?line=455'>456</a>\u001b[0m os\u001b[39m.\u001b[39mmakedirs(output_dir, exist_ok\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[1;32m--> <a href='file:///c%3A/Users/pitiw/miniconda3/envs/argument/lib/site-packages/simpletransformers/ner/ner_model.py?line=457'>458</a>\u001b[0m global_step, training_details \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrain(\n\u001b[0;32m    <a href='file:///c%3A/Users/pitiw/miniconda3/envs/argument/lib/site-packages/simpletransformers/ner/ner_model.py?line=458'>459</a>\u001b[0m     train_dataset,\n\u001b[0;32m    <a href='file:///c%3A/Users/pitiw/miniconda3/envs/argument/lib/site-packages/simpletransformers/ner/ner_model.py?line=459'>460</a>\u001b[0m     output_dir,\n\u001b[0;32m    <a href='file:///c%3A/Users/pitiw/miniconda3/envs/argument/lib/site-packages/simpletransformers/ner/ner_model.py?line=460'>461</a>\u001b[0m     show_running_loss\u001b[39m=\u001b[39;49mshow_running_loss,\n\u001b[0;32m    <a href='file:///c%3A/Users/pitiw/miniconda3/envs/argument/lib/site-packages/simpletransformers/ner/ner_model.py?line=461'>462</a>\u001b[0m     eval_data\u001b[39m=\u001b[39;49meval_data,\n\u001b[0;32m    <a href='file:///c%3A/Users/pitiw/miniconda3/envs/argument/lib/site-packages/simpletransformers/ner/ner_model.py?line=462'>463</a>\u001b[0m     \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs,\n\u001b[0;32m    <a href='file:///c%3A/Users/pitiw/miniconda3/envs/argument/lib/site-packages/simpletransformers/ner/ner_model.py?line=463'>464</a>\u001b[0m )\n\u001b[0;32m    <a href='file:///c%3A/Users/pitiw/miniconda3/envs/argument/lib/site-packages/simpletransformers/ner/ner_model.py?line=465'>466</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msave_model(model\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel)\n\u001b[0;32m    <a href='file:///c%3A/Users/pitiw/miniconda3/envs/argument/lib/site-packages/simpletransformers/ner/ner_model.py?line=467'>468</a>\u001b[0m logger\u001b[39m.\u001b[39minfo(\n\u001b[0;32m    <a href='file:///c%3A/Users/pitiw/miniconda3/envs/argument/lib/site-packages/simpletransformers/ner/ner_model.py?line=468'>469</a>\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39m Training of \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m model complete. Saved to \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(\n\u001b[0;32m    <a href='file:///c%3A/Users/pitiw/miniconda3/envs/argument/lib/site-packages/simpletransformers/ner/ner_model.py?line=469'>470</a>\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39margs\u001b[39m.\u001b[39mmodel_type, output_dir\n\u001b[0;32m    <a href='file:///c%3A/Users/pitiw/miniconda3/envs/argument/lib/site-packages/simpletransformers/ner/ner_model.py?line=470'>471</a>\u001b[0m     )\n\u001b[0;32m    <a href='file:///c%3A/Users/pitiw/miniconda3/envs/argument/lib/site-packages/simpletransformers/ner/ner_model.py?line=471'>472</a>\u001b[0m )\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\argument\\lib\\site-packages\\simpletransformers\\ner\\ner_model.py:763\u001b[0m, in \u001b[0;36mNERModel.train\u001b[1;34m(self, train_dataset, output_dir, show_running_loss, eval_data, test_data, verbose, **kwargs)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/pitiw/miniconda3/envs/argument/lib/site-packages/simpletransformers/ner/ner_model.py?line=759'>760</a>\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    <a href='file:///c%3A/Users/pitiw/miniconda3/envs/argument/lib/site-packages/simpletransformers/ner/ner_model.py?line=760'>761</a>\u001b[0m     loss\u001b[39m.\u001b[39mbackward()\n\u001b[1;32m--> <a href='file:///c%3A/Users/pitiw/miniconda3/envs/argument/lib/site-packages/simpletransformers/ner/ner_model.py?line=762'>763</a>\u001b[0m tr_loss \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m loss\u001b[39m.\u001b[39;49mitem()\n\u001b[0;32m    <a href='file:///c%3A/Users/pitiw/miniconda3/envs/argument/lib/site-packages/simpletransformers/ner/ner_model.py?line=763'>764</a>\u001b[0m \u001b[39mif\u001b[39;00m (step \u001b[39m+\u001b[39m \u001b[39m1\u001b[39m) \u001b[39m%\u001b[39m args\u001b[39m.\u001b[39mgradient_accumulation_steps \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m    <a href='file:///c%3A/Users/pitiw/miniconda3/envs/argument/lib/site-packages/simpletransformers/ner/ner_model.py?line=764'>765</a>\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39margs\u001b[39m.\u001b[39mfp16:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from simpletransformers.ner import NERModel, NERArgs\n",
    "\n",
    "# Configure the model\n",
    "ner_args = NERArgs()\n",
    "ner_args.train_batch_size = 12\n",
    "ner_args.evaluate_during_training = False\n",
    "ner_args.overwrite_output_dir = True\n",
    "ner_args.num_train_epochs = 100 #10\n",
    "\n",
    "\n",
    "model = NERModel(\n",
    "    \"bert\", \"monsoon-nlp/bert-base-thai\", args=ner_args, use_cuda=torch.cuda.is_available(), labels=_NER_TAGS\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "model.train_model(train_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:08<00:00,  8.54s/it]\n",
      "Running Evaluation: 100%|██████████| 18/18 [00:02<00:00,  7.04it/s]\n",
      "C:\\Users\\pitiw\\miniconda3\\envs\\argument\\lib\\site-packages\\seqeval\\metrics\\sequence_labeling.py:171: UserWarning: B_C seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "C:\\Users\\pitiw\\miniconda3\\envs\\argument\\lib\\site-packages\\seqeval\\metrics\\sequence_labeling.py:171: UserWarning: I_C seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "C:\\Users\\pitiw\\miniconda3\\envs\\argument\\lib\\site-packages\\seqeval\\metrics\\sequence_labeling.py:171: UserWarning: B_P seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "C:\\Users\\pitiw\\miniconda3\\envs\\argument\\lib\\site-packages\\seqeval\\metrics\\sequence_labeling.py:171: UserWarning: I_P seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 2.5283145805199942,\n",
       " 'precision': 0.069164265129683,\n",
       " 'recall': 0.23529411764705882,\n",
       " 'f1_score': 0.1069042316258352}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluate the model\n",
    "result, model_outputs, preds_list = model.eval_model(test_)\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ดู รายละเอียด งาน ดีกว่า ครับ   สำหรับ ผม   ผม ว่า   เซเว่น   หนัก เอาเรื่อง อยู่   ถ้า เป็น ผม เอง นะ   ผม เลือก ร้า นอ เม ซอน ครับ     เพราะ รายละเอียด งาน ไม่ เยอะ   ไม่ จุกจิก มาก   ถ้า เซเว่น   ปม ว่า น่าจะ ต้อง ทำงาน เป็น กะ   และ ไหนจะ เช็ค ของ   เช็ค สต๊อก   อื่นๆ อีก   เห็น พนักงาน มี บ่น เยอะ เลย ครับ   ต้อง รับผิดชอบ สินค้า อะไร แบบนี้ ด้วย   คือ ผม มองว่า ปัญหา จุกจิก มัน เยอะ กว่า ร้า นอ เม ซอน นะ   (คห สต. )  \n",
      "[('ดู', 'O'), ('รายละเอียด', 'O'), ('งาน', 'O'), ('ดีกว่า', 'O'), ('ครับ', 'O'), (' ', 'O'), ('สำหรับ', 'O'), ('ผม', 'O'), (' ', 'O'), ('ผม', 'O'), ('ว่า', 'O'), (' ', 'O'), ('เซเว่น', 'O'), (' ', 'O'), ('หนัก', 'O'), ('เอาเรื่อง', 'O'), ('อยู่', 'O'), (' ', 'O'), ('ถ้า', 'O'), ('เป็น', 'O'), ('ผม', 'O'), ('เอง', 'O'), ('นะ', 'O'), (' ', 'O'), ('ผม', 'B-c'), ('เลือก', 'I-c'), ('ร้า', 'I-c'), ('นอ', 'I-c'), ('เม', 'I-c'), ('ซอน', 'I-c'), ('ครับ', 'I-c'), (' ', 'I-c'), (' ', 'O'), ('เพราะ', 'B-p'), ('รายละเอียด', 'I-p'), ('งาน', 'I-p'), ('ไม่', 'I-p'), ('เยอะ', 'I-p'), (' ', 'I-p'), ('ไม่', 'I-p'), ('จุกจิก', 'I-p'), ('มาก', 'I-p'), (' ', 'I-p'), ('ถ้า', 'I-p'), ('เซเว่น', 'I-p'), (' ', 'I-p'), ('ปม', 'I-p'), ('ว่า', 'I-p'), ('น่าจะ', 'I-p'), ('ต้อง', 'I-p'), ('ทำงาน', 'I-p'), ('เป็น', 'I-p'), ('กะ', 'I-p'), (' ', 'I-p'), ('และ', 'I-p'), ('ไหนจะ', 'I-p'), ('เช็ค', 'I-p'), ('ของ', 'I-p'), (' ', 'I-p'), ('เช็ค', 'I-p'), ('สต๊อก', 'I-p'), (' ', 'I-p'), ('อื่นๆ', 'I-p'), ('อีก', 'I-p'), (' ', 'I-p'), ('เห็น', 'I-p'), ('พนักงาน', 'I-p'), ('มี', 'I-p'), ('บ่น', 'I-p'), ('เยอะ', 'I-p'), ('เลย', 'I-p'), ('ครับ', 'I-p'), (' ', 'I-p'), ('ต้อง', 'I-p'), ('รับผิดชอบ', 'I-p'), ('สินค้า', 'I-p'), ('อะไร', 'I-p'), ('แบบนี้', 'I-p'), ('ด้วย', 'I-p'), (' ', 'I-p'), ('คือ', 'I-p'), ('ผม', 'I-p'), ('มองว่า', 'I-p'), ('ปัญหา', 'I-p'), ('จุกจิก', 'I-p'), ('มัน', 'I-p'), ('เยอะ', 'I-p'), ('กว่า', 'I-p'), ('ร้า', 'I-p'), ('นอ', 'I-p'), ('เม', 'I-p'), ('ซอน', 'I-p'), ('นะ', 'I-p'), (' ', 'I-p'), ('(คห', 'I-p'), ('สต.', 'I-p'), (')', 'I-p'), (' ', 'I-p')]\n"
     ]
    }
   ],
   "source": [
    "idx = 60\n",
    "test_pred = \" \".join(list(map(lambda word: word[0], test_sents[idx])))\n",
    "print(test_pred)\n",
    "print(test_sents[idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:07<00:00,  7.88s/it]\n",
      "Running Prediction: 100%|██████████| 1/1 [00:00<00:00,  4.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'ดู': 'B_C'}, {'รายละเอียด': 'I_C'}, {'งาน': 'I_C'}, {'ดีกว่า': 'I_C'}, {'ครับ': 'I_C'}, {'สำหรับ': 'I_C'}, {'ผม': 'I_C'}, {'ผม': 'I_C'}, {'ว่า': 'I_C'}, {'เซเว่น': 'I_C'}, {'หนัก': 'I_C'}, {'เอาเรื่อง': 'I_C'}, {'อยู่': 'I_C'}, {'ถ้า': 'I_C'}, {'เป็น': 'I_C'}, {'ผม': 'I_C'}, {'เอง': 'I_C'}, {'นะ': 'I_C'}, {'ผม': 'I_C'}, {'เลือก': 'I_C'}, {'ร้า': 'I_C'}, {'นอ': 'I_P'}, {'เม': 'I_C'}, {'ซอน': 'I_C'}, {'ครับ': 'I_C'}, {'เพราะ': 'B_P'}, {'รายละเอียด': 'I_P'}, {'งาน': 'I_P'}, {'ไม่': 'I_P'}, {'เยอะ': 'I_P'}, {'ไม่': 'I_P'}, {'จุกจิก': 'I_P'}, {'มาก': 'I_P'}, {'ถ้า': 'I_P'}, {'เซเว่น': 'I_P'}, {'ปม': 'I_P'}, {'ว่า': 'I_P'}, {'น่าจะ': 'I_P'}, {'ต้อง': 'I_P'}, {'ทำงาน': 'I_P'}, {'เป็น': 'I_P'}, {'กะ': 'I_P'}, {'และ': 'I_P'}, {'ไหนจะ': 'I_P'}, {'เช็ค': 'I_P'}, {'ของ': 'I_P'}, {'เช็ค': 'I_P'}, {'สต๊อก': 'I_P'}, {'อื่นๆ': 'I_P'}, {'อีก': 'I_P'}, {'เห็น': 'I_P'}, {'พนักงาน': 'I_P'}, {'มี': 'I_P'}, {'บ่น': 'I_P'}, {'เยอะ': 'I_P'}, {'เลย': 'I_P'}, {'ครับ': 'O'}, {'ต้อง': 'O'}, {'รับผิดชอบ': 'I_P'}, {'สินค้า': 'O'}, {'อะไร': 'I_P'}, {'แบบนี้': 'O'}, {'ด้วย': 'O'}, {'คือ': 'O'}, {'ผม': 'O'}, {'มองว่า': 'O'}, {'ปัญหา': 'I_P'}, {'จุกจิก': 'O'}, {'มัน': 'I_P'}, {'เยอะ': 'I_P'}, {'กว่า': 'I_P'}, {'ร้า': 'O'}, {'นอ': 'I_P'}, {'เม': 'O'}, {'ซอน': 'O'}, {'นะ': 'O'}, {'(คห': 'O'}, {'สต.': 'O'}, {')': 'O'}]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Make predictions with the model\n",
    "predictions, raw_outputs = model.predict([test_pred])\n",
    "print(predictions[0]) "
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "a6dc3a5d5e5e7987cc7d18355d6f408e2f42f41b0aca7d07c9009e9d98d8dd16"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 ('argument')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
