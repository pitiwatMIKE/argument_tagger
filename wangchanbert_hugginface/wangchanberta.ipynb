{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "task = \"ner\" # Should be one of \"ner\", \"pos\" or \"chunk\"\n",
    "model_checkpoint = \"airesearch/wangchanberta-base-att-spm-uncased\"\n",
    "batch_size = 12\n",
    "label_list = ['O', 'B-c', 'I-c', 'B-p', 'I-p']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dill\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "552\n",
      "138\n",
      "[('ถ้า', 'JSBR', 'B-c'), ('เดินทาง', 'VACT', 'I-c'), ('กลางคืน', 'NCMN', 'I-c'), ('ก็', 'JSBR', 'I-c'), ('รถทัวร์', 'NCMN', 'I-c'), ('ครับ', 'NCMN', 'I-c'), (' ', 'PUNC', 'I-c'), (' ', 'PUNC', 'O'), ('เพราะ', 'JSBR', 'B-p'), ('รถ', 'NCMN', 'I-p'), ('ไม่', 'NEG', 'I-p'), ('เยอะ', 'VSTA', 'I-p'), (' ', 'PUNC', 'I-p'), ('ความเสี่ยง', 'NCMN', 'I-p'), ('การ', 'FIXN', 'I-p'), ('เกิด', 'VSTA', 'I-p'), ('อุบัติ', 'NCMN', 'I-p'), ('ห', 'NCMN', 'I-p'), ('ตุ', 'NCMN', 'I-p'), ('ก็', 'JSBR', 'I-p'), ('น้อย', 'VATT', 'I-p'), ('(', 'PUNC', 'I-p'), ('มั้ง', 'JCRG', 'I-p'), (')', 'PUNC', 'I-p'), (' ', 'PUNC', 'I-p'), (' ', 'PUNC', 'O'), ('ถ้า', 'JSBR', 'B-c'), ('กลางวัน', 'NCMN', 'I-c'), ('ก็', 'JSBR', 'I-c'), ('เครื่องบิน', 'VSTA', 'I-c'), ('ครับ', 'NCMN', 'I-c'), (' ', 'PUNC', 'I-c'), (' ', 'PUNC', 'O'), ('เพราะ', 'JSBR', 'B-p'), (' ', 'PUNC', 'I-p'), ('มัน', 'PPRS', 'I-p'), ('ใช้เวลา', 'VSTA', 'I-p'), ('น้อย', 'ADVN', 'I-p'), ('จะ', 'XVBM', 'I-p'), ('ได้', 'XVAM', 'I-p'), ('มี', 'VSTA', 'I-p'), ('เวลา', 'NCMN', 'I-p'), ('ระหว่าง', 'RPRE', 'I-p'), ('วัน', 'NCMN', 'I-p'), ('เยอะ', 'NCMN', 'I-p'), ('ๆ', 'PUNC', 'I-p'), (' ', 'PUNC', 'I-p')]\n"
     ]
    }
   ],
   "source": [
    "path_name = \"../dataset/data/\"\n",
    "\n",
    "with open(path_name + 'comment-pos.data', 'rb') as file:\n",
    "    datatofile = dill.load(file)\n",
    "\n",
    "tagged_sents = []\n",
    "for data in datatofile:\n",
    "    text_inside = []\n",
    "    for word, pos, label in data:\n",
    "        if word.strip() == '':\n",
    "            text_inside.append((' ', pos, label))\n",
    "        else:\n",
    "            text_inside.append((word, pos, label))\n",
    "    tagged_sents.append(text_inside)\n",
    "\n",
    "train_sents, test_sents = train_test_split(tagged_sents, test_size=0.2, random_state=42)\n",
    "print(len(train_sents))\n",
    "print(len(test_sents))\n",
    "print(train_sents[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_to_dict(data):\n",
    "    datasets = dict()\n",
    "    datasets['id'] = []\n",
    "    datasets['tokens'] = []\n",
    "    datasets['pos_tags'] = []\n",
    "    datasets['ner_tags'] = []\n",
    "    for i, sent in enumerate(data):\n",
    "        _word = []\n",
    "        _label = []\n",
    "        _pos = []\n",
    "        for word, pos, label in sent:\n",
    "            _word.append(word)\n",
    "            _label.append(label)\n",
    "            _pos.append(pos)\n",
    "        datasets['id'].append(i)\n",
    "        datasets['tokens'].append(_word)\n",
    "        datasets['pos_tags'].append(_pos)\n",
    "        datasets['ner_tags'].append([label_list.index(l) for l in _label])\n",
    "    return datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pitiw\\miniconda3\\envs\\wangchan\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['id', 'tokens', 'pos_tags', 'ner_tags'],\n",
       "        num_rows: 552\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['id', 'tokens', 'pos_tags', 'ner_tags'],\n",
       "        num_rows: 138\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import DatasetDict, Dataset,Sequence, Features, Value, ClassLabel\n",
    "\n",
    "ft = Features({\n",
    "    'id': Value(\"int32\"),\n",
    "    'tokens': Sequence(Value(\"string\")), \n",
    "    'pos_tags': Sequence(Value(\"string\")),\n",
    "    'ner_tags': Sequence(ClassLabel(names=label_list))\n",
    "    })\n",
    "\n",
    "datasets = DatasetDict({\n",
    "    'train': Dataset.from_dict(data_to_dict(train_sents), features=ft),\n",
    "    'test': Dataset.from_dict(data_to_dict(test_sents), features=ft)\n",
    "})\n",
    "\n",
    "datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len: 5\n",
      "['O', 'B-c', 'I-c', 'B-p', 'I-p']\n"
     ]
    }
   ],
   "source": [
    "label_list = datasets[\"train\"].features[f\"{task}_tags\"].feature.names\n",
    "print('len:', len(label_list))\n",
    "print(label_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>tokens</th>\n",
       "      <th>pos_tags</th>\n",
       "      <th>ner_tags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>451</td>\n",
       "      <td>[เรา, เห็นด้วย, กับ, ทำ, เ, เท้ง, ถูกกฎหมาย,  , เเต่, ไม่, เห็นด้วย, กับ, การ, ทำ, เ, เท้ง, นะคะ,  , จขกท,  , งง,  , ไหม, เอ่ย,  , เพราะ, เรา, เห็น, ว่า,  , ตอนนี้, มัน, ก็, มี, ทำ, เ, เท้ง, เถื่อน,  , ซึ่ง, มัน, ไม่, ปลอดภัย,  , ทั้ง, เเม่(, เด็ก, คง, ไม่, ปลอดภัย, อยู่, เเล้ว),  , เ, เละ, สังคม,  , เรา, เห็น, ด้วยว่า, ควร, มี, คลีนิค, ทำ, เ, เท้ง, ถูกกฎหมาย,  , เเต่, ควร, มี, นักจิตวิทยา, ประเมิน, ความพร้อม, ของ, เเม่, ก่อน,  , ไม่, ใช่, เพราะ, หา, ทางออก, ไม่, ได้,  , เเต่, ไม่, มีความรู้, เรื่อง, ทางออก, รึเปล่า,  , ควร, ต้อง, ให้ความรู้, กับ, คน, ที่จะ, ทำ, ...]</td>\n",
       "      <td>[PPRS, VACT, RPRE, VACT, NCMN, NCMN, NCMN, PUNC, NCMN, NEG, VSTA, RPRE, FIXN, VACT, NCMN, NCMN, NCMN, PUNC, NCMN, PUNC, NCMN, PUNC, NCMN, NCMN, PUNC, JSBR, PPRS, VSTA, JSBR, PUNC, JSBR, PPRS, JSBR, VSTA, VACT, NCMN, NCMN, RPRE, PUNC, JSBR, PPRS, NEG, VSTA, PUNC, JCRG, NCMN, NCMN, XVBM, NEG, VSTA, XVAE, NCMN, PUNC, NCMN, NCMN, NCMN, PUNC, PPRS, VSTA, JSBR, XVMM, VSTA, NCMN, VACT, NCMN, NCMN, NCMN, PUNC, NCMN, XVMM, VSTA, NCMN, VSTA, NCMN, RPRE, NCMN, RPRE, PUNC, NEG, VSTA, JSBR, VACT, NCMN, NEG, XVAE, PUNC, NCMN, NEG, VSTA, NCMN, NCMN, NCMN, PUNC, XVMM, XVMM, VACT, RPRE, NCMN, JSBR, VACT, ...]</td>\n",
       "      <td>[B-c, I-c, I-c, I-c, I-c, I-c, I-c, I-c, I-c, I-c, I-c, I-c, I-c, I-c, I-c, I-c, I-c, O, O, O, O, O, O, O, O, B-p, I-p, I-p, I-p, I-p, I-p, I-p, I-p, I-p, I-p, I-p, I-p, I-p, I-p, I-p, I-p, I-p, I-p, I-p, I-p, I-p, I-p, I-p, I-p, I-p, I-p, I-p, I-p, I-p, I-p, I-p, I-p, I-p, I-p, I-p, I-p, I-p, I-p, I-p, I-p, I-p, I-p, I-p, I-p, I-p, I-p, I-p, I-p, I-p, I-p, I-p, I-p, I-p, I-p, I-p, I-p, I-p, I-p, I-p, I-p, I-p, I-p, I-p, I-p, I-p, I-p, I-p, I-p, I-p, I-p, I-p, I-p, I-p, I-p, I-p, ...]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>413</td>\n",
       "      <td>[ที่, ราคา, ยางพารา, ต่ำ, ลง, เพราะ, จีน, ซื้อ, น้อยลง, ไง, ครับ,  , ตอนนี้, ที่, จีน, ก็, ปลูก, เอง, เยอะ,  , นอกจากนี้, จีน, ยัง, เช่า, ที่, ลาว,  , เขมร,  , และ, อื่นๆ, ปลูก, อีก,  , เลย, ทำให้, ตอนนี้, ยาง, ล้น, โลก, แล้ว,  , ถ้า, ผู้ซื้อ, รายใหญ่, อย่าง, จีน,  , เลิก, ซื้อ,  , ก็, จบ,  , จีน, ผลิต, รถ, ยนตร์, ในประเทศ, ปี, ละ,  , ประมาณ,  , เกือบ,  , 30,  , ล้าน, คัน]</td>\n",
       "      <td>[PREL, NCMN, VATT, VATT, XVAE, JSBR, NCMN, NCMN, ADVN, NCMN, NCMN, PUNC, DDAC, PREL, NPRP, JSBR, VACT, PDMN, NCMN, NCMN, JSBR, XVBM, XVBM, VSTA, PREL, VSTA, NCMN, NCMN, PUNC, JCRG, DIAC, VACT, ADVN, PUNC, XVAE, VACT, DDAC, VACT, VSTA, NCMN, XVAE, PUNC, JSBR, NCMN, FIXN, FIXV, VATT, PUNC, NCMN, VACT, PUNC, JSBR, VSTA, PUNC, NPRP, VACT, NCMN, DIBQ, RPRE, NCMN, RPRE, PUNC, DIBQ, PUNC, DIBQ, NCMN, NCNM, PUNC, NCMN, CNIT]</td>\n",
       "      <td>[B-c, I-c, I-c, I-c, I-c, B-p, I-p, I-p, I-p, I-p, I-p, O, B-p, I-p, I-p, I-p, I-p, I-p, I-p, I-p, I-p, I-p, I-p, I-p, I-p, I-p, I-p, I-p, I-p, I-p, I-p, I-p, I-p, O, B-c, I-c, I-c, I-c, I-c, I-c, I-c, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>402</td>\n",
       "      <td>[ระดับ, การพัฒนา, ของ, ประเทศ, ใน, อาเซียน, ค่อนข้างจะ, ต่างกัน, พอสมควร, ครับ,  , ถ้า, เทียบ, เขตเมือง, ก็, มี, ทั้งที่, เรา, เจริญ, กว่า, และ, เพื่อนบ้าน, เจริญ, กว่า,  ,  , เช่น, เทียบ, เมือง, ใหญ่, ที่, มี, ความเจริญ, ลำดับ, ต้น,  , ๆ,  , ของ, แต่ละ, ประเทศ, ใน, อาเซียน,  , เช่น, เทียบ, เขตเมือง, ระหว่าง, ชลบุรี, -, พัทยา, หรือ, เชียงใหม่, ของ, ไทย,  , ปีนัง, ของ, มาเลเซีย,  , เซ, บู, ของ, ฟิลิปปินส์,  , มัณฑะเลย์, ของ, เมียนมาร์,  , ความเจริญ, ใน, ด้าน, เศรษฐกิจ,  , ระบบ, สาธารณูปโภค,  , ระบบ, ขนส่ง, สาธารณะ,  , สนามบิน,  , ผม, ให้, ปีนัง, ดี, ที่สุด,  , รอง, ลงมา, ก็, ชลบุรี, -, พัทยา, /, เชียงใหม่,  , เซ, บู, ...]</td>\n",
       "      <td>[NCMN, NCMN, RPRE, NCMN, RPRE, NCMN, NCMN, VSTA, ADVN, NCMN, PUNC, JSBR, VACT, NCMN, JSBR, VSTA, JSBR, PPRS, VSTA, JCMP, JCRG, NCMN, VATT, JCMP, PUNC, PUNC, RPRE, VACT, NCMN, VATT, PREL, VSTA, NCMN, NCMN, NCMN, PUNC, NCMN, PUNC, RPRE, DIBQ, CNIT, RPRE, NCMN, PUNC, RPRE, VACT, NCMN, RPRE, NCMN, PUNC, NCMN, JCRG, NCMN, RPRE, NPRP, VACT, NCMN, RPRE, NPRP, PUNC, NCMN, NCMN, RPRE, NCMN, PUNC, NCMN, RPRE, NCMN, PUNC, NCMN, RPRE, NCMN, NCMN, PUNC, NCMN, NCMN, PUNC, NCMN, NCMN, NCMN, PUNC, NCMN, PUNC, PPRS, JSBR, NCMN, VATT, ADVN, NCMN, VATT, ADVN, JSBR, NCMN, PUNC, NCMN, PUNC, NPRP, PUNC, NCMN, NCMN, ...]</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, O, O, B-c, I-c, I-c, I-c, I-c, I-c, I-c, I-c, I-c, I-c, I-c, I-c, I-c, I-c, O, B-p, I-p, I-p, I-p, I-p, I-p, I-p, I-p, I-p, I-p, I-p, I-p, I-p, I-p, I-p, I-p, I-p, I-p, I-p, I-p, I-p, I-p, I-p, I-p, I-p, I-p, I-p, I-p, I-p, I-p, I-p, I-p, I-p, I-p, I-p, I-p, I-p, I-p, I-p, I-p, I-p, I-p, I-p, I-p, I-p, I-p, I-p, I-p, I-p, I-p, I-p, I-p, I-p, I-p, I-p, I-p, I-p, I-p, I-p, I-p, I-p, I-p, I-p, I-p, I-p, I-p, I-p, I-p, I-p, I-p, I-p, I-p, I-p, I-p, ...]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>372</td>\n",
       "      <td>[ยอม, เป็น, คนโง่, ครับ, เพราะ, ยอมรับ, ว่า, มีเรื่อง, ที่, เรา, ยัง, ไม่, รู้, อีก, มาก,  , แต่, มี, เงื่อนไข, ว่า, กลุ่ม, คนเก่ง, นั้น, ต้อง, ให้เกียรติ, เรา,  , เป็น, คนดี, และ, ไม่, อี, โก้, สูง, ด้วย, ครับ]</td>\n",
       "      <td>[NCMN, VSTA, NCMN, NCMN, JSBR, VACT, JSBR, NCMN, PREL, PPRS, XVBM, NEG, VSTA, ADVN, ADVN, PUNC, JCRG, VSTA, NCMN, JSBR, NCMN, NCMN, DDAC, XVMM, VACT, PPRS, PUNC, VSTA, NCMN, JCRG, NEG, VSTA, NCMN, VATT, RPRE, NCMN]</td>\n",
       "      <td>[B-c, I-c, I-c, I-c, B-p, I-p, I-p, I-p, I-p, I-p, I-p, I-p, I-p, I-p, I-p, I-p, I-p, I-p, I-p, I-p, I-p, I-p, I-p, I-p, I-p, I-p, I-p, I-p, I-p, I-p, I-p, I-p, I-p, I-p, I-p, I-p]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7</td>\n",
       "      <td>[ถ้า, เอา, จีน,  , เกาหลีเหนือ,  , อาหรับ, แถบ, ๆ, นู้น, มา, รวม, ๆ, กัน,  ,  , น่าจะ, ได้, ค่ะ,  ,  , อยาก, ให้, ยุ่น, อยู่, ฝ่าย, นี้, ด้วยกัน,  , พี่, กัน, เจ้า, ปัญหา, จะ, ได้, จบ, ๆ, ไป]</td>\n",
       "      <td>[JSBR, VACT, NPRP, PUNC, NPRP, PUNC, NPRP, NCMN, PUNC, NCMN, XVAE, VACT, PUNC, ADVN, PUNC, PUNC, XVMM, VSTA, NCMN, PUNC, PUNC, NCMN, JSBR, VSTA, XVAE, NCMN, DDAC, ADVN, PUNC, NCMN, ADVN, ADVN, NCMN, XVBM, VSTA, VSTA, VACT, XVAE]</td>\n",
       "      <td>[B-p, I-p, I-p, I-p, I-p, I-p, I-p, I-p, I-p, I-p, I-p, I-p, I-p, I-p, I-p, O, B-c, I-c, I-c, I-c, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>479</td>\n",
       "      <td>[เลือก,  , ซัว, เร, ส,  , เพราะ, ครบเครื่อง, กว่า,  , ทุกอย่าง, ฟรี, คลิก,  , จุดโทษ,  , เตะ, มุม,  , ได้, หมด,  , มี, แถม,  , ลูก, ตุกติก,  , เรียก, จุดโทษ,  , ใบแดง,  , แถม, ร่างกาย,  , ดี, อึด, ทน,  , ไม่ค่อย, เจ็บ,  , ง่ายๆ,  ]</td>\n",
       "      <td>[VACT, PUNC, NCMN, NCMN, NCMN, PUNC, JSBR, NCMN, JCMP, NCMN, NCMN, NCMN, NCMN, PUNC, NCMN, PUNC, NCMN, NCMN, PUNC, XVAE, ADVN, PUNC, VSTA, NCMN, PUNC, NCMN, NCMN, PUNC, VACT, NCMN, PUNC, NCMN, PUNC, NCMN, NCMN, PUNC, VATT, JCMP, NCMN, PUNC, NCMN, NCMN, PUNC, NCMN, PUNC]</td>\n",
       "      <td>[B-c, I-c, I-c, I-c, I-c, I-c, B-p, I-p, I-p, I-p, I-p, I-p, I-p, I-p, I-p, I-p, I-p, I-p, I-p, I-p, I-p, I-p, I-p, I-p, I-p, I-p, I-p, I-p, I-p, I-p, I-p, I-p, I-p, I-p, I-p, I-p, I-p, I-p, I-p, I-p, I-p, I-p, I-p, I-p, I-p]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>462</td>\n",
       "      <td>[ทำไม, ถึง, มองว่า,  , E-sport,  , เป็น, กีฬา, ?,  , ....,  , ผม, อ่าน, ข่าว, ที่, โอลิมปิก, บรรจุ,  , E-sport,  , ลง, ใน, กีฬา,  , อืม, !,  , ก็, โอลิมปิก, บรรจุ,  , E-sport,  , ลง, ใน, กีฬา, ไง]</td>\n",
       "      <td>[NCMN, RPRE, NCMN, PUNC, NCMN, PUNC, VSTA, NCMN, PUNC, NCMN, PUNC, PUNC, PPRS, VACT, NCMN, PREL, NCMN, VACT, PUNC, NCMN, PUNC, XVAE, RPRE, NCMN, PUNC, NCMN, PUNC, PUNC, JSBR, NCMN, VACT, PUNC, NCMN, PUNC, XVAE, RPRE, NCMN, NCMN]</td>\n",
       "      <td>[B-c, I-c, I-c, I-c, I-c, I-c, I-c, I-c, I-c, I-c, I-c, I-c, I-c, I-c, I-c, I-c, I-c, I-c, I-c, I-c, I-c, I-c, I-c, I-c, O, O, O, O, B-p, I-p, I-p, I-p, I-p, I-p, I-p, I-p, I-p, I-p]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>500</td>\n",
       "      <td>[จำเป็น, ครับ,  , ชุดนักเรียน, ช่วย, ลด, รายจ่าย, ของ, ผู้ปกครอง,  , และ, ความเหลื่อมล้ำ, ของ, เด็ก]</td>\n",
       "      <td>[VSTA, NCMN, PUNC, NCMN, VACT, VACT, NCMN, RPRE, NCMN, PUNC, JCRG, NCMN, RPRE, NCMN]</td>\n",
       "      <td>[B-c, I-c, O, B-p, I-p, I-p, I-p, I-p, I-p, I-p, I-p, I-p, I-p, I-p]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>197</td>\n",
       "      <td>[คนใช้,  , Samsung,  , มากกว่า,  , เพราะ, มี, หลาย, ระดับ,  , โหล, ต, ภาพ,  , โหล, ต, เพลง,  , ต่อ, คอม, ง่าย, ดี,  ]</td>\n",
       "      <td>[NCMN, PUNC, NCMN, PUNC, JCRG, PUNC, JSBR, VSTA, DIBQ, NCMN, PUNC, NCMN, NCMN, NCMN, PUNC, NCMN, NCMN, NCMN, PUNC, RPRE, NCMN, ADVN, VATT, PUNC]</td>\n",
       "      <td>[B-c, I-c, I-c, I-c, I-c, I-c, B-p, I-p, I-p, I-p, I-p, I-p, I-p, I-p, I-p, I-p, I-p, I-p, I-p, I-p, I-p, I-p, I-p, I-p]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>457</td>\n",
       "      <td>[Austin, ,,  , TX,  ,  , เพราะ, ไม่, มี, ภาษีรายได้,  , เมือง, ไม่, ใหญ่, มาก,  , สวย, กว่า, เมือง, ใหญ่, อื่น, ใน,  , เทกซัส,  , อย่าง, ดัลลัส,  , หรือ,  , ฮิ, วส์, ตัน,  , อาการ, ไม่,  , รุนแรง, เท่า, นิวยอร์ก,  , แบะ, ภาษี, ไม่, แพง, เท่า, แคลิฟอร์เนีย,  ]</td>\n",
       "      <td>[NCMN, PUNC, PUNC, NCMN, PUNC, PUNC, JSBR, NEG, VSTA, NCMN, PUNC, NCMN, NEG, VATT, ADVN, PUNC, VATT, JCMP, NCMN, VATT, DIAC, RPRE, PUNC, NCMN, NCMN, FIXV, VATT, PUNC, JCRG, PUNC, NCMN, NCMN, NCMN, PUNC, NCMN, NEG, PUNC, NCMN, VSTA, NCMN, PUNC, NCMN, NCMN, NEG, VSTA, VSTA, NCMN, PUNC]</td>\n",
       "      <td>[B-c, I-c, I-c, I-c, I-c, O, B-p, I-p, I-p, I-p, I-p, I-p, I-p, I-p, I-p, I-p, I-p, I-p, I-p, I-p, I-p, I-p, I-p, I-p, I-p, I-p, I-p, I-p, I-p, I-p, I-p, I-p, I-p, I-p, I-p, I-p, I-p, I-p, I-p, I-p, I-p, I-p, I-p, I-p, I-p, I-p, I-p, I-p]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from datasets import ClassLabel, Sequence\n",
    "import random\n",
    "import pandas as pd\n",
    "from IPython.display import display, HTML\n",
    "\n",
    "def show_random_elements(dataset, num_examples=10):\n",
    "    assert num_examples <= len(dataset), \"Can't pick more elements than there are in the dataset.\"\n",
    "    picks = []\n",
    "    for _ in range(num_examples):\n",
    "        pick = random.randint(0, len(dataset)-1)\n",
    "        while pick in picks:\n",
    "            pick = random.randint(0, len(dataset)-1)\n",
    "        picks.append(pick)\n",
    "    \n",
    "    df = pd.DataFrame(dataset[picks])\n",
    "    for column, typ in dataset.features.items():\n",
    "        if isinstance(typ, ClassLabel):\n",
    "            df[column] = df[column].transform(lambda i: typ.names[i])\n",
    "        elif isinstance(typ, Sequence) and isinstance(typ.feature, ClassLabel):\n",
    "            df[column] = df[column].transform(lambda x: [typ.feature.names[i] for i in x])\n",
    "    display(HTML(df.to_html()))\n",
    "\n",
    "show_random_elements(datasets[\"train\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess The data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer  \n",
    "    \n",
    "tokenizer = AutoTokenizer.from_pretrained(model_checkpoint, model_max_length=126)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import transformers\n",
    "assert isinstance(tokenizer, transformers.PreTrainedTokenizerFast)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ใส่', 'กระดาษ', 'จะ', 'ทำให้', 'จำได้', 'ง่าย', ' ', ' ', 'เพราะ', ' ', 'ทำ', 'ใน', 'คอม', ' ', 'มีระบบ', ' ', 'ใส่', 'คำสั่ง', 'ให้', 'เอง', ' ', 'ถึง', 'เวลา', 'สอบ', 'สมัครงาน', 'บาง', 'ที่', ' ', 'ให้', 'เขียน', 'ลง', 'กระดาษ', ' ', 'ก็', 'จะ', 'เขียน', 'ไม่', 'ออก', ' ']\n"
     ]
    }
   ],
   "source": [
    "example = datasets[\"train\"][2]\n",
    "print(example[\"tokens\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['<s>', '▁', 'ใส่', '▁', 'กระดาษ', '▁จะ', '▁ทําให้', '▁', 'จําได้', '▁', 'ง่าย', '▁', '▁', '▁เพราะ', '▁', '▁ทํา', '▁', 'ใน', '▁', 'คอม', '▁', '▁', 'มีระบบ', '▁', '▁', 'ใส่', '▁', 'คําสั่ง', '▁', 'ให้', '▁', 'เอง', '▁', '▁', 'ถึง', '▁เวลา', '▁', 'สอบ', '▁', 'สมัครงาน', '▁บาง', '▁', 'ที่', '▁', '▁', 'ให้', '▁', 'เขียน', '▁', 'ลง', '▁', 'กระดาษ', '▁', '▁ก็', '▁จะ', '▁', 'เขียน', '▁ไม่', '▁', 'ออก', '▁', '</s>']\n"
     ]
    }
   ],
   "source": [
    "tokenized_input = tokenizer(example[\"tokens\"], is_split_into_words=True)\n",
    "tokens = tokenizer.convert_ids_to_tokens(tokenized_input[\"input_ids\"])\n",
    "print(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "62 62\n"
     ]
    }
   ],
   "source": [
    "word_ids = tokenized_input.word_ids()\n",
    "aligned_labels = [-100 if i is None else example[f\"{task}_tags\"][i] for i in word_ids]\n",
    "print(len(aligned_labels), len(tokenized_input[\"input_ids\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_all_tokens = True\n",
    "\n",
    "def tokenize_and_align_labels(examples):\n",
    "    tokenized_inputs = tokenizer(examples[\"tokens\"], truncation=True, is_split_into_words=True)\n",
    "\n",
    "    labels = []\n",
    "    for i, label in enumerate(examples[f\"{task}_tags\"]):\n",
    "        word_ids = tokenized_inputs.word_ids(batch_index=i)\n",
    "        previous_word_idx = None\n",
    "        label_ids = []\n",
    "        for word_idx in word_ids:\n",
    "            # Special tokens have a word id that is None. We set the label to -100 so they are automatically\n",
    "            # ignored in the loss function.\n",
    "            if word_idx is None:\n",
    "                label_ids.append(-100)\n",
    "            # We set the label for the first token of each word.\n",
    "            elif word_idx != previous_word_idx:\n",
    "                label_ids.append(label[word_idx])\n",
    "            # For the other tokens in a word, we set the label to either the current label or -100, depending on\n",
    "            # the label_all_tokens flag.\n",
    "            else:\n",
    "                label_ids.append(label[word_idx] if label_all_tokens else -100)\n",
    "            previous_word_idx = word_idx\n",
    "\n",
    "        labels.append(label_ids)\n",
    "\n",
    "    tokenized_inputs[\"labels\"] = labels\n",
    "    return tokenized_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': [[5, 10, 10539, 10, 15486, 10, 6850, 10, 4738, 13764, 10, 1599, 10, 499, 10, 711, 10, 1599, 10, 662, 10, 711, 1739, 222, 6989, 10, 111, 10, 158, 10, 6]], 'attention_mask': [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]], 'labels': [[-100, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, -100]]}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenize_and_align_labels(datasets['train'][:1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  1.81ba/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  7.75ba/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['id', 'tokens', 'pos_tags', 'ner_tags', 'input_ids', 'attention_mask', 'labels'],\n",
       "        num_rows: 552\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['id', 'tokens', 'pos_tags', 'ner_tags', 'input_ids', 'attention_mask', 'labels'],\n",
       "        num_rows: 138\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_datasets = datasets.map(tokenize_and_align_labels, batched=True)\n",
    "tokenized_datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fine-tuning the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at airesearch/wangchanberta-base-att-spm-uncased were not used when initializing CamembertForTokenClassification: ['lm_head.layer_norm.weight', 'lm_head.dense.bias', 'lm_head.decoder.bias', 'lm_head.layer_norm.bias', 'lm_head.dense.weight', 'lm_head.bias', 'lm_head.decoder.weight']\n",
      "- This IS expected if you are initializing CamembertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing CamembertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of CamembertForTokenClassification were not initialized from the model checkpoint at airesearch/wangchanberta-base-att-spm-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForTokenClassification, TrainingArguments, Trainer\n",
    "\n",
    "model = AutoModelForTokenClassification.from_pretrained(model_checkpoint, num_labels=len(label_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = model_checkpoint.split(\"/\")[-1]\n",
    "args = TrainingArguments(\n",
    "    f\"{model_name}-finetuned-{task}\",\n",
    "    evaluation_strategy = \"epoch\",\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=batch_size,\n",
    "    per_device_eval_batch_size=batch_size,\n",
    "    num_train_epochs=3,\n",
    "    weight_decay=0.01,\n",
    "    save_strategy='epoch',\n",
    "    save_total_limit=2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import DataCollatorForTokenClassification\n",
    "\n",
    "data_collator = DataCollatorForTokenClassification(tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_metric\n",
    "metric = load_metric(\"seqeval\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'c': {'precision': 1.0, 'recall': 1.0, 'f1': 1.0, 'number': 1},\n",
       " 'p': {'precision': 1.0, 'recall': 1.0, 'f1': 1.0, 'number': 1},\n",
       " 'overall_precision': 1.0,\n",
       " 'overall_recall': 1.0,\n",
       " 'overall_f1': 1.0,\n",
       " 'overall_accuracy': 1.0}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = [label_list[i] for i in example[f\"{task}_tags\"]]\n",
    "metric.compute(predictions=[labels], references=[labels])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def compute_metrics(p):\n",
    "    predictions, labels = p\n",
    "    predictions = np.argmax(predictions, axis=2)\n",
    "\n",
    "    # Remove ignored index (special tokens)\n",
    "    true_predictions = [\n",
    "        [label_list[p] for (p, l) in zip(prediction, label) if l != -100]\n",
    "        for prediction, label in zip(predictions, labels)\n",
    "    ]\n",
    "    true_labels = [\n",
    "        [label_list[l] for (p, l) in zip(prediction, label) if l != -100]\n",
    "        for prediction, label in zip(predictions, labels)\n",
    "    ]\n",
    "\n",
    "    results = metric.compute(predictions=true_predictions, references=true_labels)\n",
    "    return {\n",
    "        \"precision\": results[\"overall_precision\"],\n",
    "        \"recall\": results[\"overall_recall\"],\n",
    "        \"f1\": results[\"overall_f1\"],\n",
    "        \"accuracy\": results[\"overall_accuracy\"],\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(\n",
    "    model,\n",
    "    args,\n",
    "    train_dataset=tokenized_datasets[\"train\"],\n",
    "    eval_dataset=tokenized_datasets[\"test\"],\n",
    "    data_collator=data_collator,\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the training set  don't have a corresponding argument in `CamembertForTokenClassification.forward` and have been ignored: id, pos_tags, tokens, ner_tags. If id, pos_tags, tokens, ner_tags are not expected by `CamembertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "C:\\Users\\pitiw\\miniconda3\\envs\\wangchan\\lib\\site-packages\\transformers\\optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "***** Running training *****\n",
      "  Num examples = 552\n",
      "  Num Epochs = 3\n",
      "  Instantaneous batch size per device = 12\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 12\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 138\n",
      " 33%|███▎      | 46/138 [00:31<00:59,  1.56it/s]The following columns in the evaluation set  don't have a corresponding argument in `CamembertForTokenClassification.forward` and have been ignored: id, pos_tags, tokens, ner_tags. If id, pos_tags, tokens, ner_tags are not expected by `CamembertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 138\n",
      "  Batch size = 12\n",
      "                                                \n",
      " 33%|███▎      | 46/138 [00:33<00:59,  1.56it/s]Saving model checkpoint to wangchanberta-base-att-spm-uncased-finetuned-ner\\checkpoint-46\n",
      "Configuration saved in wangchanberta-base-att-spm-uncased-finetuned-ner\\checkpoint-46\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.1402631998062134, 'eval_precision': 0.00816326530612245, 'eval_recall': 0.014251781472684086, 'eval_f1': 0.010380622837370243, 'eval_accuracy': 0.48090918153723455, 'eval_runtime': 2.556, 'eval_samples_per_second': 53.991, 'eval_steps_per_second': 4.695, 'epoch': 1.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in wangchanberta-base-att-spm-uncased-finetuned-ner\\checkpoint-46\\pytorch_model.bin\n",
      "tokenizer config file saved in wangchanberta-base-att-spm-uncased-finetuned-ner\\checkpoint-46\\tokenizer_config.json\n",
      "Special tokens file saved in wangchanberta-base-att-spm-uncased-finetuned-ner\\checkpoint-46\\special_tokens_map.json\n",
      " 67%|██████▋   | 92/138 [01:12<00:33,  1.38it/s]The following columns in the evaluation set  don't have a corresponding argument in `CamembertForTokenClassification.forward` and have been ignored: id, pos_tags, tokens, ner_tags. If id, pos_tags, tokens, ner_tags are not expected by `CamembertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 138\n",
      "  Batch size = 12\n",
      "                                                \n",
      " 67%|██████▋   | 92/138 [01:17<00:33,  1.38it/s]Saving model checkpoint to wangchanberta-base-att-spm-uncased-finetuned-ner\\checkpoint-92\n",
      "Configuration saved in wangchanberta-base-att-spm-uncased-finetuned-ner\\checkpoint-92\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.0517568588256836, 'eval_precision': 0.017474633596392335, 'eval_recall': 0.07363420427553444, 'eval_f1': 0.028246013667425966, 'eval_accuracy': 0.5459076861728641, 'eval_runtime': 4.959, 'eval_samples_per_second': 27.828, 'eval_steps_per_second': 2.42, 'epoch': 2.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in wangchanberta-base-att-spm-uncased-finetuned-ner\\checkpoint-92\\pytorch_model.bin\n",
      "tokenizer config file saved in wangchanberta-base-att-spm-uncased-finetuned-ner\\checkpoint-92\\tokenizer_config.json\n",
      "Special tokens file saved in wangchanberta-base-att-spm-uncased-finetuned-ner\\checkpoint-92\\special_tokens_map.json\n",
      "100%|██████████| 138/138 [02:00<00:00,  1.50it/s]The following columns in the evaluation set  don't have a corresponding argument in `CamembertForTokenClassification.forward` and have been ignored: id, pos_tags, tokens, ner_tags. If id, pos_tags, tokens, ner_tags are not expected by `CamembertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 138\n",
      "  Batch size = 12\n",
      "                                                 \n",
      "100%|██████████| 138/138 [02:02<00:00,  1.50it/s]Saving model checkpoint to wangchanberta-base-att-spm-uncased-finetuned-ner\\checkpoint-138\n",
      "Configuration saved in wangchanberta-base-att-spm-uncased-finetuned-ner\\checkpoint-138\\config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.02717125415802, 'eval_precision': 0.015748031496062992, 'eval_recall': 0.057007125890736345, 'eval_f1': 0.024678663239074552, 'eval_accuracy': 0.5508922340743695, 'eval_runtime': 2.865, 'eval_samples_per_second': 48.167, 'eval_steps_per_second': 4.188, 'epoch': 3.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in wangchanberta-base-att-spm-uncased-finetuned-ner\\checkpoint-138\\pytorch_model.bin\n",
      "tokenizer config file saved in wangchanberta-base-att-spm-uncased-finetuned-ner\\checkpoint-138\\tokenizer_config.json\n",
      "Special tokens file saved in wangchanberta-base-att-spm-uncased-finetuned-ner\\checkpoint-138\\special_tokens_map.json\n",
      "Deleting older checkpoint [wangchanberta-base-att-spm-uncased-finetuned-ner\\checkpoint-46] due to args.save_total_limit\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "100%|██████████| 138/138 [02:11<00:00,  1.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train_runtime': 131.0899, 'train_samples_per_second': 12.633, 'train_steps_per_second': 1.053, 'train_loss': 1.0893198649088542, 'epoch': 3.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=138, training_loss=1.0893198649088542, metrics={'train_runtime': 131.0899, 'train_samples_per_second': 12.633, 'train_steps_per_second': 1.053, 'train_loss': 1.0893198649088542, 'epoch': 3.0})"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the evaluation set  don't have a corresponding argument in `CamembertForTokenClassification.forward` and have been ignored: id, pos_tags, tokens, ner_tags. If id, pos_tags, tokens, ner_tags are not expected by `CamembertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 138\n",
      "  Batch size = 12\n",
      "100%|██████████| 12/12 [00:02<00:00,  4.45it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 1.02717125415802,\n",
       " 'eval_precision': 0.015748031496062992,\n",
       " 'eval_recall': 0.057007125890736345,\n",
       " 'eval_f1': 0.024678663239074552,\n",
       " 'eval_accuracy': 0.5508922340743695,\n",
       " 'eval_runtime': 2.918,\n",
       " 'eval_samples_per_second': 47.292,\n",
       " 'eval_steps_per_second': 4.112,\n",
       " 'epoch': 3.0}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the test set  don't have a corresponding argument in `CamembertForTokenClassification.forward` and have been ignored: id, pos_tags, tokens, ner_tags. If id, pos_tags, tokens, ner_tags are not expected by `CamembertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Prediction *****\n",
      "  Num examples = 138\n",
      "  Batch size = 12\n",
      "100%|██████████| 12/12 [00:02<00:00,  5.93it/s]"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'c': {'precision': 0.008818342151675485,\n",
       "  'recall': 0.0211864406779661,\n",
       "  'f1': 0.012453300124533,\n",
       "  'number': 236},\n",
       " 'p': {'precision': 0.019853709508881923,\n",
       "  'recall': 0.10270270270270271,\n",
       "  'f1': 0.03327495621716287,\n",
       "  'number': 185},\n",
       " 'overall_precision': 0.015748031496062992,\n",
       " 'overall_recall': 0.057007125890736345,\n",
       " 'overall_f1': 0.024678663239074552,\n",
       " 'overall_accuracy': 0.5508922340743695}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions, labels, _ = trainer.predict(tokenized_datasets[\"test\"])\n",
    "predictions = np.argmax(predictions, axis=2)\n",
    "\n",
    "# Remove ignored index (special tokens)\n",
    "true_predictions = [\n",
    "    [label_list[p] for (p, l) in zip(prediction, label) if l != -100]\n",
    "    for prediction, label in zip(predictions, labels)\n",
    "]\n",
    "true_labels = [\n",
    "    [label_list[l] for (p, l) in zip(prediction, label) if l != -100]\n",
    "    for prediction, label in zip(predictions, labels)\n",
    "]\n",
    "\n",
    "results = metric.compute(predictions=true_predictions, references=true_labels)\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['<s>', '▁สําหรับ', '▁เรา', '▁', 'จบ', '▁', 'โท', '▁', '▁', 'ที่', '▁', '▁', 'ออสเตรเลีย', '▁', '▁และ', '▁', 'นิวซีแลนด์', '▁', '▁เรา', '▁', 'ว่า', '▁', 'คุ้ม', '▁', 'ยิ่งกว่า', '▁', 'คุ้ม', '▁', '▁', 'เปลี่ยน', '▁ชีวิต', '▁', '▁', 'มุมมอง', '▁', '▁', 'ทัศนคติ', '▁', '▁', 'คอนเน', 'ค', '▁', 'ชั่น', '▁', '▁งาน', '▁', '▁', 'เงิน', '▁แน่นอน', '▁', 'ว่า', '▁', 'ใช้เวลา', '▁', 'ค่ะ', '▁', '▁แต่', '▁ถ้า', '▁', 'มีโอกาส', '▁', 'ไป', '▁', 'เถอะ', '▁', 'ค่ะ', '▁', '▁คน', '▁มี', '▁', 'ความสามารถ', '▁', 'มักจะ', '▁มี', '▁', 'หนทาง', '▁', 'ต่อไป', '▁', 'เรื่อยๆ', '</s>']\n"
     ]
    }
   ],
   "source": [
    "idx = 20\n",
    "show_text = tokenizer(tokenized_datasets[\"test\"][idx]['tokens'], is_split_into_words=True)\n",
    "print(tokenizer.convert_ids_to_tokens(show_text['input_ids']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pred: ['O', 'I-c', 'I-c', 'I-c', 'I-c', 'I-c', 'I-c', 'I-c', 'I-c', 'I-c', 'I-c', 'I-p', 'I-c', 'I-c', 'I-c', 'I-c', 'I-c', 'I-p', 'I-p', 'I-p', 'I-c', 'I-c', 'I-p', 'I-p', 'I-p', 'I-p', 'I-p', 'I-p', 'I-p', 'I-p', 'I-p', 'I-p', 'I-p', 'I-p', 'I-p', 'I-p', 'I-p', 'I-p', 'I-p', 'I-p', 'I-p', 'I-p', 'I-p', 'I-p', 'I-p', 'I-p', 'I-p', 'O', 'I-p', 'I-p', 'I-p', 'I-p', 'I-p', 'I-p', 'O', 'I-p', 'O', 'I-p', 'O', 'I-p', 'I-p', 'I-p', 'O', 'I-p', 'I-p', 'I-p', 'I-p', 'I-p', 'I-p', 'I-p', 'I-p', 'I-p', 'I-p', 'I-p', 'I-p', 'I-p', 'I-p', 'I-p', 'I-p']\n",
      "true: ['B-c', 'I-c', 'I-c', 'I-c', 'I-c', 'I-c', 'I-c', 'I-c', 'I-c', 'I-c', 'I-c', 'I-c', 'I-c', 'I-c', 'I-c', 'I-c', 'I-c', 'I-c', 'I-c', 'I-c', 'I-c', 'I-c', 'I-c', 'I-c', 'I-c', 'I-c', 'O', 'B-p', 'B-p', 'I-p', 'I-p', 'I-p', 'I-p', 'I-p', 'I-p', 'I-p', 'I-p', 'I-p', 'I-p', 'I-p', 'I-p', 'I-p', 'I-p', 'I-p', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-c', 'I-c', 'I-c', 'I-c', 'I-c', 'I-c', 'I-c', 'I-c', 'I-c', 'I-c', 'O', 'B-p', 'I-p', 'I-p', 'I-p', 'I-p', 'I-p', 'I-p', 'I-p', 'I-p', 'I-p', 'I-p', 'I-p', 'I-p']\n"
     ]
    }
   ],
   "source": [
    "print('pred:', true_predictions[idx])\n",
    "print('true:', true_labels[idx])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ฉัน', 'ชอบ', 'หมา', 'เพราะ', 'มัน', 'น่ารัก', 'มาก', 'ๆ', ' ', 'เลย']\n"
     ]
    }
   ],
   "source": [
    "from pythainlp.tokenize import word_tokenize\n",
    "text_list = word_tokenize('ฉันชอบหมาเพราะมันน่ารักมากๆ เลย')\n",
    "print(text_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_ids': [5, 264, 1879, 10, 1022, 474, 661, 5840, 10, 82, 10, 34, 10, 10, 48, 6], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}\n",
      "['<s>', '▁ฉัน', '▁ชอบ', '▁', 'หมา', '▁เพราะ', '▁มัน', '▁น่ารัก', '▁', 'มาก', '▁', 'ๆ', '▁', '▁', 'เลย', '</s>']\n"
     ]
    }
   ],
   "source": [
    "_input_token = tokenizer(text_list, is_split_into_words=True)\n",
    "_word_token = tokenizer.convert_ids_to_tokens(_input_token[\"input_ids\"])\n",
    "print(_input_token)\n",
    "print(_word_token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Prediction *****\n",
      "  Num examples = 1\n",
      "  Batch size = 12\n",
      "13it [00:09,  2.37s/it]                        "
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[4, 4, 2, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4]], dtype=int64)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred = trainer.predict([_input_token])[0]\n",
    "pred = np.argmax(pred, axis=2)\n",
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['I-p', 'I-c', 'I-p', 'I-p', 'I-p', 'I-p', 'I-p', 'I-p', 'I-p', 'I-p', 'I-p', 'I-p', 'I-p', 'I-p', 'I-p']\n"
     ]
    }
   ],
   "source": [
    "true_predictions = [\n",
    "    [label_list[p] for (p, l) in zip(prediction, label) if l != -100]\n",
    "    for prediction, label in zip(pred, labels)\n",
    "][0]\n",
    "print(true_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15\n",
      "16\n"
     ]
    }
   ],
   "source": [
    "print(len(true_predictions))\n",
    "print(len(_word_token))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('▁ฉัน', 'I-p')\n",
      "('▁ชอบ', 'I-c')\n",
      "('▁', 'I-p')\n",
      "('หมา', 'I-p')\n",
      "('▁เพราะ', 'I-p')\n",
      "('▁มัน', 'I-p')\n",
      "('▁น่ารัก', 'I-p')\n",
      "('▁', 'I-p')\n",
      "('มาก', 'I-p')\n",
      "('▁', 'I-p')\n",
      "('ๆ', 'I-p')\n",
      "('▁', 'I-p')\n",
      "('▁', 'I-p')\n",
      "('เลย', 'I-p')\n"
     ]
    }
   ],
   "source": [
    "for w, l in zip(_word_token[1:-1], true_predictions):\n",
    "  print((w, l))"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "018e0a3ac4678c6eee4f5b6012f6866bd583f46fe819b31cdc8524b9233bdcf3"
  },
  "kernelspec": {
   "display_name": "Python 3.8.13 ('wangchan')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
